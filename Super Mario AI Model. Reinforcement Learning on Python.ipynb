{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb29500b",
   "metadata": {},
   "source": [
    "<h1>1. Установка среды Марио</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d76599",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Правообладатель gym-super-mario-bros\n",
    "#   @misc{gym-super-mario-bros,\n",
    "#   author = {Christian Kauten},\n",
    "#   howpublished = {GitHub},\n",
    "#   title = {{S}uper {M}ario {B}ros for {O}pen{AI} {G}ym},\n",
    "#   URL = {https://github.com/Kautenja/gym-super-mario-bros},\n",
    "#   year = {2018},"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbfa614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym_super_mario_bros #загружаем игру\n",
    "from nes_py.wrappers import JoypadSpace #загружаем Joypad.Wrapper\n",
    "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT #загрузка управления"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76247d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#установка игры\n",
    "env = gym_super_mario_bros.make('SuperMarioBros-v0')\n",
    "env = JoypadSpace(env, SIMPLE_MOVEMENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e18658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #цикл для запуска игры\n",
    "# done = True \n",
    "# #шаг в каждый шаг обучения\n",
    "# for step in range(50000):\n",
    "#     if done:\n",
    "#         #начало игры\n",
    "#         state = env.reset()\n",
    "#     state, reward, done, info = env.step(env.action_space.sample()) #рандомайзер действий\n",
    "#     env.render() #показ на экран\n",
    "\n",
    "# env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65643ee1",
   "metadata": {},
   "source": [
    "<h1>2. Подготовка среды</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af51f5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym.wrappers import GrayScaleObservation #FrameStack нужен для отправления в стек предыдущих шагов цикла\n",
    "#GrayScaleObservation нужен для уменьшения количества данных(цвета) для ускорения работы\n",
    "from stable_baselines3.common.vec_env import VecFrameStack, DummyVecEnv\n",
    "#работа с векторами (векторизация)\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a455a3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#установка основной среды\n",
    "env = gym_super_mario_bros.make('SuperMarioBros-v0')\n",
    "# Упрощение комманд\n",
    "env = JoypadSpace(env, SIMPLE_MOVEMENT)\n",
    "#Эффект серого\n",
    "env = GrayScaleObservation(env, keep_dim=True)\n",
    "#Dummy Environment\n",
    "env = DummyVecEnv([lambda: env])\n",
    "#Отправка кадров в стэк\n",
    "env = VecFrameStack(env, 4, channels_order='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59afebc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "state = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52727c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "state, reward, done, info = env.step([5]) #рандомайзер действий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46e4f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,16))\n",
    "for i in range(state.shape[3]):\n",
    "    plt.subplot(1,4,i+1)\n",
    "    plt.imshow(state[0][:,:,i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffb70b5",
   "metadata": {},
   "source": [
    "<h1>3. Испытание модели обучения с подкреплением(RL)</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9a415f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os #для оперирования с путями (path management)\n",
    "from stable_baselines3 import PPO #PPO обладет некоторыми дополнительными алгоритмами машинного обучения\n",
    "from stable_baselines3.common.callbacks import BaseCallback #для сохранения модели каждые n раз (бэкап)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2900d604",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainAndLoggingCallback(BaseCallback):\n",
    "    \n",
    "    def __init__(self, check_freq, save_path, verbose=1):\n",
    "        super(TrainAndLoggingCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def _init_callback(self):\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self):\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            model_path = os.path.join(self.save_path, 'best_model_{}'.format(self.n_calls))\n",
    "            self.model.save(model_path)\n",
    "\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ae9535",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_DIR = './train/'\n",
    "LOG_DIR = './logs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a12cf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Сохранение нашей модели каждые n раз (в нашем случае 10 000)\n",
    "callback = TrainAndLoggingCallback(check_freq=50000, save_path=CHECKPOINT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6910da4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Запуск Модели\n",
    "model = PPO('CnnPolicy', env, verbose=1, tensorboard_log=LOG_DIR, learning_rate=0.000001, \n",
    "            n_steps=512) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373a3478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Начало Обучения Модели\n",
    "model.learn(total_timesteps=1000000, callback=callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b89ced",
   "metadata": {},
   "source": [
    "<h1>4. Тестирование Модели</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de43f283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заргузка модели\n",
    "model = PPO.load('./train/best_model_50000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c62889d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Начало Игры\n",
    "state = env.reset()\n",
    "# Цикл по игре\n",
    "while True: \n",
    "    \n",
    "    action, _ = model.predict(state)\n",
    "    state, reward, done, info = env.step(action)\n",
    "    env.render()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('TensorFlow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "f765389c2de4ab75433d53ddca25c5a84eb9c6e4df9203133eac281a00ac28b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
